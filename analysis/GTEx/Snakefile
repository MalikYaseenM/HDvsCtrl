#snakemake --nolock -np --cluster "qsub -P mlhd -cwd -pe omp {threads}" --jobs 50
#expand("sorted_reads/{sample}.{replicate}.bam", sample=SAMPLES, replicate=[0, 1])
import os, pandas, glob
include: 'GTEX_samples.py'

#REFERENCES
truseq=os.path.abspath('../reference/TruSeq3-PE.fa')
indexdir=os.path.abspath('../reference/GENCODE_v25_star_index')
salmonpath=os.path.abspath(
    '../reference/gencode.v25.transcripts.salmon_quasi_index/')
pathtogtf=os.path.abspath(
    '../reference/gencode.v25.annotation.gtf')
hd_counts=glob.glob(os.path.abspath('../../samples/*/quant.genes.sf'))
workdir: '../../samples/GTEx/'         
STAR=expand('{sample}__trimP__STAR.Aligned.sortedByCoord.out.bam',
            sample = samples)
# need to run fastqc_files first
fastqc_files=expand('{sample}_R{replicate}_fastqc.zip',
                    sample=samples, replicate=[1,2])
rename_fastqc=expand('{sample}_R{replicate}__fastqc.zip',
                     sample=samples, replicate=[1,2])
trim_error=expand('{sample}__trimerror.log', sample=samples)
salmon_counts=expand('{sample}__salmon__counts', sample= samples)
salmon_log= expand('{sample}__salmon__counts/libParams/flenDist.txt',
                   sample= samples)
quant_sf = glob.glob('*/quant.genes.sf')
total_counts = quant_sf + hd_counts
STAR_Log = expand('{sample}__trimP__STAR.Log.final.out', sample=samples)

rule all:
    input:
        # fastqc_files,
        # rename_fastqc,
        #trim_error,
        #salmon_counts,
        # "multiqc_report.html",
        "all_salmon_quant.tsv"
        #STAR
rule fastqc:
    input:
        fastq= "{sample}.fastq.gz"
    output:
        zip= "{sample}_fastqc.zip",
        html= "{sample}_fastqc.html"
    threads:8
    shell:
        "fastqc -t {threads} {input.fastq}"
rule renamefastqc:
    input:
        zip="{sample}_fastqc.zip",
        html="{sample}_fastqc.html"
    output:
        zip="{sample}__fastqc.zip",
        html="{sample}__fastqc.html"
    shell:
        "mv {input.zip} {output.zip} && "
        "mv {input.html} {output.html}"

rule trimmomatic:
    input:
        #read1 = expand('{sample}_R1.fastq.gz', sample = samples),
        #read2 = expand('{sample}_R2.fastq.gz', sample = samples),
        read1="{sample}_R1.fastq.gz",
        read2="{sample}_R2.fastq.gz",
        adapter = truseq
    output:
        read1p = "{sample}__R1__trimP.fastq.gz",
        read1u = "{sample}__R1__trimU.fastq.gz",
        read2p = "{sample}__R2__trimP.fastq.gz",
        read2u = "{sample}__R2__trimU.fastq.gz",
        trimlog = "{sample}__trimerror.log"
    log:
        "{sample}__trimerror.log"
    shell:
        "trimmomatic PE -phred33 "
        "{input.read1} {input.read2} "
        "{output.read1p} {output.read1u} {output.read2p} {output.read2u} "
        "ILLUMINACLIP:{input.adapter}:2:30:10 LEADING:3 TRAILING:3 "
        "SLIDINGWINDOW:4:15 MINLEN:36 2> {log} "

rule salmon:
    input:
        READ1="{sample}_R1.fastq.gz",
        READ2="{sample}_R2.fastq.gz",
        gtf=pathtogtf,
        index= salmonpath
    output:
        salmon_out='{sample}__salmon__counts'
    threads: 8
    shell:
        "salmon quant --index {input.index} -g {input.gtf} "
        "-l A -1 {input.READ1} -2 {input.READ2} --output {output.salmon_out} "
        "-p {threads} "

rule concat_salmon:
    input:
        quant = total_counts
    output:
        matrix= 'all_salmon_quant.tsv'
    run:
        mat = None
        for fn in input.quant:
            if 'GTEX' in os.path.dirname(fn):                
                sample_name = os.path.dirname(fn).replace(
                    '__salmon__counts', '')
            else:
                sample_name = os.path.basename(os.path.dirname(fn)).replace(
                    '__salmon__counts', '')
            col_names = ['gene_id', 'Length', 'EffectiveLength', 'TPM', '{}'.
                         format(sample_name)]
            df = pandas.read_csv(fn, sep='\t', skiprows=1, names=col_names)

            if mat is None:
                df = df.drop(['Length', 'EffectiveLength', 'TPM'], axis=1)
                mat = df
            else:
                mat = pandas.concat([mat, df.iloc[:, 4:]], axis=1)
            mat.to_csv(output[0], sep='\t', index=False)

rule STAR:
    input:
        index= indexdir,
        read1="{sample}__R1__trimP.fastq.gz",
        read2="{sample}__R2__trimP.fastq.gz"
    output:
        sorted_bam='{sample}__trimP__STAR.Aligned.sortedByCoord.out.bam',
        finallog='{sample}__trimP__STAR.Log.final.out'
    params:
        prefix='{sample}__trimP__STAR.'
    threads:8
    shell:
        "STAR --runThreadN {threads} "
        "--runMode alignReads "
        "--genomeDir {input.index} "
        "--readFilesIn {input.read1} {input.read2} "
        "--readFilesCommand zcat --outFileNamePrefix {params.prefix} "
        "--outSAMtype BAM SortedByCoordinate "
	"--limitBAMsortRAM 57409410454"

rule multiqc:
    input:
        fqc=rename_fastqc,
        trim=trim_error,
        salmon=salmon_counts,
        STAR_Out= STAR_Log
    output:
        report="multiqc_report.html"
    params:
        prefix="multiqc_report."
    shell:
        "export LC_ALL=en_US.utf-8 export LANG=$LC_ALL && "

        "multiqc {input.fqc} {input.trim} {input.salmon} {input.STAR_Out}"














